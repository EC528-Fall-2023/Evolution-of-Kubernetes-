{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OJst4VQFmhCK"
      },
      "outputs": [],
      "source": [
        "# This is the code to parse the .spdx file for the SBOMs\n",
        "# It creates 3 .csv files\n",
        "# spdx_output.csv: Files independent of packages\n",
        "# relationships_output.csv: Relationship between differentr packages\n",
        "# packages_output.csv: Contains different packages\n",
        "\n",
        "#works from 1.15 to recent\n",
        "\n",
        "import csv\n",
        "import glob\n",
        "import pandas as pd\n",
        "import linecache\n",
        "\n",
        "# Define a variable to track the current entry\n",
        "\n",
        "def cleanup(unwantedTerms,line):\n",
        "  for i in unwantedTerms:\n",
        "    line = line.replace(i,\"\")\n",
        "  return line\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to fill in the lists that will later be used to make our 3 csvs\n",
        "def fill_lists(spdx_file_path):\n",
        "  with open(spdx_file_path,'r') as spdx_file:\n",
        "      #counter to keep track of how many dependencies a version has\n",
        "      #iterate line by line and use \"name\" as indicator of\n",
        "      counter = 0\n",
        "      for line_num,line in enumerate(spdx_file):\n",
        "        line = line.strip()\n",
        "        if line.startswith('\"name\"'):\n",
        "          #cleanup symbols we do not need\n",
        "          line = cleanup(['\"name\":',',','\"','\"',' '],line)\n",
        "          #filter out two exceptions and append\n",
        "          if (line[0:10] == \"kubernetes\"): versionName = line\n",
        "          if (line[0:10] != \"kubernetes\" and line[0:4] != \"SBOM\"):\n",
        "            dependencyName.append(line)\n",
        "            #getting spdxID\n",
        "            #print(linecache.getline(spdx_file_path,count))\n",
        "            spdxID.append(cleanup(['\"SPDXID\":',',','\"','\"',' '],linecache.getline(spdx_file_path,line_num)))\n",
        "            #counter keeping track of total amt of dependencies\n",
        "            counter+=1\n",
        "        if line.startswith('\"versionInfo\"'):\n",
        "          line = cleanup(['\"versionInfo\":',',','\"','\"',' '],line)\n",
        "          #filter out exceptions\n",
        "          if (line != \"\"):dependencyVersion.append(line)\n",
        "      for count in range(counter):\n",
        "        versionNameList.append(versionName)"
      ],
      "metadata": {
        "id": "vkbiWWhA6Mk9"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_csv_dependencies(file_path):\n",
        "  #csv path for dependencies\n",
        "\n",
        "  #writing into csv\n",
        "  with open(file_path,'w') as csv_file:\n",
        "    fieldnames = ['dependencyName-Version','dependencyName','dependencyVersion','SPDXID']\n",
        "    csv_writer = csv.DictWriter(csv_file,fieldnames=fieldnames)\n",
        "    csv_writer.writeheader()\n",
        "    for count in range(len(dependencyName)):\n",
        "        csv_writer.writerow({\n",
        "            'dependencyName-Version': dependencyName[count] + '-' + dependencyVersion[count],\n",
        "            'dependencyName': dependencyName[count],\n",
        "            'dependencyVersion': dependencyVersion[count],\n",
        "            'SPDXID': spdxID[count]\n",
        "            })"
      ],
      "metadata": {
        "id": "4A_1B3ft6RLn"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_csv_map(file_path):\n",
        "  #csv path for mapping\n",
        "  #writing into csv\n",
        "  with open(file_path,'w') as csv_file:\n",
        "    fieldnames = ['kubernetesVersion','dependencyName-Version']\n",
        "    csv_writer = csv.DictWriter(csv_file,fieldnames=fieldnames)\n",
        "    csv_writer.writeheader()\n",
        "    for count in range(len(dependencyName)):\n",
        "        csv_writer.writerow({\n",
        "            'kubernetesVersion': versionNameList[count],\n",
        "            'dependencyName-Version': dependencyName[count] + '-' + dependencyVersion[count]\n",
        "            })"
      ],
      "metadata": {
        "id": "2tZJxnDF6U-g"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_csv_kubeversion(file_path):\n",
        "  #csv path for kube versions\n",
        "  #writing into csv\n",
        "  with open(file_path,'w') as csv_file:\n",
        "    fieldnames = ['kubernetesVersion']\n",
        "    csv_writer = csv.DictWriter(csv_file,fieldnames=fieldnames)\n",
        "    csv_writer.writeheader()\n",
        "    for count in range(len(versionNameList)):\n",
        "      csv_writer.writerow({\n",
        "          'kubernetesVersion': versionNameList[count]\n",
        "\n",
        "          })"
      ],
      "metadata": {
        "id": "zuQwRYaO6Xcd"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###RUN THIS TO GENERATE\n",
        "\n",
        "path = '/content/*.*'\n",
        "# Create lists to store SPDX information\n",
        "versionName = None\n",
        "versionNameList = []\n",
        "dependencyName = []\n",
        "dependencyVersion = []\n",
        "spdxID = []\n",
        "\n",
        "dependenciescsv_file_path = '/content/drive/MyDrive/EC528Colab/dependencies_entry.csv'\n",
        "mappingcsv_file_path = '/content/drive/MyDrive/EC528Colab/version_dependencies_mapping.csv'\n",
        "kubeversioncsv_file_path = '/content/drive/MyDrive/EC528Colab/version_entry.csv'\n",
        "\n",
        "#iterate through all files in this path\n",
        "for file in glob.glob(path):\n",
        "  fill_lists(file)\n",
        "\n",
        "#make csv using respective functions\n",
        "make_csv_dependencies(dependenciescsv_file_path)\n",
        "make_csv_map(mappingcsv_file_path)\n",
        "make_csv_kubeversion(kubeversioncsv_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "uvxw4pt8TceW"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###RUN THIS TO CLEAN\n",
        "\n",
        "dependenciesDF = pd.read_csv(dependenciescsv_file_path)\n",
        "mappingDF = pd.read_csv(mappingcsv_file_path)\n",
        "kubeversionDF = pd.read_csv(kubeversioncsv_file_path)\n",
        "\n",
        "#function to clean the csv of duplicate rows\n",
        "dependenciesDF = dependenciesDF.drop_duplicates()\n",
        "mappingDF = mappingDF.drop_duplicates()\n",
        "kubeversionDF = kubeversionDF.drop_duplicates()\n",
        "\n",
        "dependenciesDF.to_csv(dependenciescsv_file_path,encoding='utf-8',index=False)\n",
        "mappingDF.to_csv(mappingcsv_file_path,encoding='utf-8',index=False)\n",
        "kubeversionDF.to_csv(kubeversioncsv_file_path,encoding='utf-8',index=False)"
      ],
      "metadata": {
        "id": "dr0sd47TY5Pz"
      },
      "execution_count": 105,
      "outputs": []
    }
  ]
}